{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from robosat.robosat.tools.train import *\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from robosat.robosat.datasets import BufferedSlippyMapDirectory\n",
    "from robosat.robosat.colors import continuous_palette_for_color\n",
    "from torchvision.transforms import Compose, Normalize\n",
    "from robosat.robosat.colors import make_palette\n",
    "from robosat.robosat.tiles import tiles_from_slippy_map\n",
    "import cv2 as cv\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from robosat.robosat.transforms import ConvertImageMode, ImageToTensor\n",
    "def parse_default():\n",
    "    parse = argparse.ArgumentParser(description=\"test\")\n",
    "    parse.add_argument(\"--batch_size\", type=int, default=1, help=\"images per batch\")\n",
    "    parse.add_argument(\"--checkpoint\", type=str, default=\"F:\\\\tmp\\\\pth\\\\checkpoint-00064-of-00300.pth\",  help=\"model checkpoint to load\")\n",
    "    parse.add_argument(\"--overlap\", type=int, default=32, help=\"tile pixel overlap to predict on\")\n",
    "    parse.add_argument(\"--tile_size\", type=int, default=448,  help=\"tile size for slippy map tiles\")\n",
    "    parse.add_argument(\"--workers\", type=int, default=0, help=\"number of workers pre-processing images\")\n",
    "    parse.add_argument(\"--tiles\", type=str, default=\"F:\\\\PyCharmWorkSpace\\\\robsat_train\\\\cat\", help=\"directory to read slippy map image tiles from\")\n",
    "    parse.add_argument(\"--probs\", type=str, default=\"F:\\\\PyCharmWorkSpace\\\\robsat_train\\\\cat_predict\", help=\"directory to save slippy map probability masks to\")\n",
    "    parse.add_argument(\"--masks\", type=str, default=\"F:\\\\PyCharmWorkSpace\\\\robsat_train\\\\cat_mask\",help=\"slippy map directory to save masks to\")\n",
    "    parse.add_argument(\"--weights\", type=float, nargs=\"+\", help=\"weights for weighted average soft-voting\")\n",
    "    parse.add_argument(\"--model\", type=str, default=\"model-unet.toml\", help=\"path to model configuration file\")\n",
    "    parse.add_argument(\"--dataset\", type=str,default=\"dataset.toml\", help=\"path to dataset configuration file\")\n",
    "    return parse.parse_args(args=[])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def predict_pic():\n",
    "    print(args.model)\n",
    "    model = load_config(args.model)\n",
    "    dataset = load_config(args.dataset)\n",
    "\n",
    "    cuda = model[\"common\"][\"cuda\"]\n",
    "\n",
    "    device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "    def map_location(storage, _):\n",
    "        return storage.cuda() if cuda else storage.cpu()\n",
    "\n",
    "    if cuda and not torch.cuda.is_available():\n",
    "        sys.exit(\"Error: CUDA requested but not available\")\n",
    "\n",
    "    num_classes = len(dataset[\"common\"][\"classes\"])\n",
    "\n",
    "    # https://github.com/pytorch/pytorch/issues/7178\n",
    "    chkpt = torch.load(args.checkpoint, map_location=map_location)\n",
    "\n",
    "    net = UNet(num_classes).to(device)\n",
    "    net = nn.DataParallel(net)\n",
    "\n",
    "    if cuda:\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    net.load_state_dict(chkpt[\"state_dict\"])\n",
    "    net.eval()\n",
    "\n",
    "    mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "\n",
    "    transform = Compose([ConvertImageMode(mode=\"RGB\"), ImageToTensor(), Normalize(mean=mean, std=std)])\n",
    "\n",
    "    directory = BufferedSlippyMapDirectory(args.tiles, transform=transform, size=args.tile_size, overlap=args.overlap)\n",
    "    assert len(directory) > 0, \"at least one tile in dataset\"\n",
    "\n",
    "    loader = DataLoader(directory, batch_size=args.batch_size, num_workers=args.workers)\n",
    "\n",
    "    # don't track tensors with autograd during prediction\n",
    "    with torch.no_grad():\n",
    "        for images, tiles in tqdm(loader, desc=\"Eval\", unit=\"batch\", ascii=True):\n",
    "            images = images.to(device)\n",
    "            outputs = net(images)\n",
    "\n",
    "            # manually compute segmentation mask class probabilities per pixel\n",
    "            probs = nn.functional.softmax(outputs, dim=1).data.cpu().numpy()\n",
    "\n",
    "            for tile, prob in zip(tiles, probs):\n",
    "                x, y, z = list(map(int, tile))\n",
    "                # we predicted on buffered tiles; now get back probs for original image\n",
    "                prob = directory.unbuffer(prob)\n",
    "\n",
    "                # Quantize the floating point probabilities in [0,1] to [0,255] and store\n",
    "                # a single-channel `.png` file with a continuous color palette attached.\n",
    "\n",
    "                assert prob.shape[0] == 2, \"single channel requires binary model\"\n",
    "                assert np.allclose(np.sum(prob, axis=0), 1.), \"single channel requires probabilities to sum up to one\"\n",
    "                foreground = prob[1:, :, :]\n",
    "\n",
    "                anchors = np.linspace(0, 1, 256)\n",
    "                quantized = np.digitize(foreground, anchors).astype(np.uint8)\n",
    "\n",
    "                palette = continuous_palette_for_color(\"pink\", 256)\n",
    "\n",
    "                out = Image.fromarray(quantized.squeeze(), mode=\"P\")\n",
    "                # cv.imshow(\"predict\",palette)\n",
    "                out.putpalette(palette)\n",
    "\n",
    "                os.makedirs(os.path.join(args.probs, str(z), str(x)), exist_ok=True)\n",
    "                path = os.path.join(args.probs, str(z), str(x), str(y) + \".png\")\n",
    "\n",
    "                out.save(path, optimize=True)\n",
    "        return\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Namespace(batch_size=1, checkpoint='F:\\\\tmp\\\\pth\\\\checkpoint-00064-of-00300.pth', dataset='dataset.toml', masks='F:\\\\PyCharmWorkSpace\\\\robsat_train\\\\cat_mask', model='model-unet.toml', overlap=32, probs='F:\\\\PyCharmWorkSpace\\\\robsat_train\\\\cat_predict', tile_size=448, tiles='F:\\\\PyCharmWorkSpace\\\\robsat_train\\\\cat', weights=None, workers=0)\n",
      "model-unet.toml\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "Eval: 100%|##########| 21/21 [00:15<00:00,  1.39batch/s]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = parse_default()\n",
    "    # main(args)\n",
    "    print(args)\n",
    "    predict_pic()# 获得预测概率\n",
    "    #mask_pic()# 形成mask遮罩\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}